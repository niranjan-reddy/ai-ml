{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from num2words import num2words\n",
    "from collections import Counter\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import operator\n",
    "import nltk\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"20_newsgroups\"\n",
    "unique_labels = ['comp.graphics', 'rec.sport.hockey', 'sci.med', 'sci.space', 'talk.politics.misc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "labels = []\n",
    "for l in unique_labels:\n",
    "    for (dirpath, dirnames, filenames) in os.walk(str(os.getcwd())+'/'+title+'/'+str(l)):\n",
    "        for i in filenames:\n",
    "            paths.append(str(dirpath)+str(\"/\")+i)\n",
    "            labels.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 5000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paths), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_doc(id):\n",
    "    file = open(paths[id], 'r', encoding='cp1250')\n",
    "    text = file.read().strip()\n",
    "    file.close()\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_numbers(k):\n",
    "    for i in range(len(k)):\n",
    "        try:\n",
    "            k[i] = num2words(int(k[i]))\n",
    "        except:\n",
    "            pass\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_freq(word):\n",
    "    c = 0\n",
    "    try:\n",
    "        c = DF[word]\n",
    "    except:\n",
    "        pass\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(pd):\n",
    "    pd = pd.str.lower()\n",
    "    pd = pd.str.replace('[{}]'.format('!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\\n\\t'), ' ')\n",
    "    pd = pd.apply(lambda x: [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(x)])\n",
    "    pd = pd.apply(lambda x: convert_numbers(x))\n",
    "    pd = pd.str.join(' ')\n",
    "    pd = pd.str.replace('[{}]'.format(string.punctuation), ' ')\n",
    "    \n",
    "#     pd = pd.apply(lambda x: [w for w in w_tokenizer.tokenize(x)])    \n",
    "    pd = pd.apply(lambda x: [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(x)])    \n",
    "    pd = pd.apply(lambda x: [item for item in x if item not in stop_words])\n",
    "#     pd = pd.apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "    return pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(predicted, true):\n",
    "    tp_tn = len([1 for i in range(len(predicted)) if predicted[i]==true[i]])\n",
    "    return tp_tn/len(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_confusion(predicted, true):\n",
    "    confusion = np.zeros((len(unique_labels), len(unique_labels))).astype(int)\n",
    "    for i in range(len(predicted)):\n",
    "        confusion[unique_labels.index(predicted[i])][unique_labels.index(true[i])] += 1\n",
    "    return confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc = 0\n",
    "# docs = []\n",
    "\n",
    "# for path in paths:\n",
    "#     file = open(path, 'r', encoding='cp1250')\n",
    "#     text = file.read().strip()\n",
    "#     file.close()\n",
    "    \n",
    "#     docs.append(text)\n",
    "    \n",
    "#     if doc%1000 == 0:\n",
    "#         print(doc)\n",
    "\n",
    "#     doc += 1\n",
    "# docs_pd = pd.DataFrame([docs, labels]).T\n",
    "# docs_pd[0] = preprocess(docs_pd[0])\n",
    "# docs_pd.to_pickle(\"docs_pd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_pd = pd.read_pickle(\"docs_pd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = docs_pd.sample(frac=0.5,random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = docs_pd.sample(frac=1,random_state=41).drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[xref, cantaloupesrvcscmuedu, scispace60876, s...</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[path, cantaloupesrvcscmuedumagnesiumclubcccmu...</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[xref, cantaloupesrvcscmuedu, talkpoliticsmisc...</td>\n",
       "      <td>talk.politics.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[path, cantaloupesrvcscmueducrabapplesrvcscmue...</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[newsgroups, recsporthockeypath, cantaloupesrv...</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0                   1\n",
       "0  [xref, cantaloupesrvcscmuedu, scispace60876, s...           sci.space\n",
       "1  [path, cantaloupesrvcscmuedumagnesiumclubcccmu...             sci.med\n",
       "2  [xref, cantaloupesrvcscmuedu, talkpoliticsmisc...  talk.politics.misc\n",
       "3  [path, cantaloupesrvcscmueducrabapplesrvcscmue...    rec.sport.hockey\n",
       "4  [newsgroups, recsporthockeypath, cantaloupesrv...    rec.sport.hockey"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[newsgroups, talkpoliticsmiscpath, cantaloupes...</td>\n",
       "      <td>talk.politics.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[newsgroups, talkpoliticsmiscpath, cantaloupes...</td>\n",
       "      <td>talk.politics.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[xref, cantaloupesrvcscmuedu, mischeadlines417...</td>\n",
       "      <td>talk.politics.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[newsgroups, scimedpath, cantaloupesrvcscmuedu...</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[xref, cantaloupesrvcscmuedu, compinfosystemsg...</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0                   1\n",
       "0  [newsgroups, talkpoliticsmiscpath, cantaloupes...  talk.politics.misc\n",
       "1  [newsgroups, talkpoliticsmiscpath, cantaloupes...  talk.politics.misc\n",
       "2  [xref, cantaloupesrvcscmuedu, mischeadlines417...  talk.politics.misc\n",
       "3  [newsgroups, scimedpath, cantaloupesrvcscmuedu...             sci.med\n",
       "4  [xref, cantaloupesrvcscmuedu, compinfosystemsg...       comp.graphics"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class_split = Counter(train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'sci.space': 499,\n",
       "         'sci.med': 505,\n",
       "         'talk.politics.misc': 499,\n",
       "         'rec.sport.hockey': 513,\n",
       "         'comp.graphics': 484})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_class_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = {}\n",
    "for i in range(train.shape[0]):\n",
    "    try:\n",
    "        m[train[1][i]] = m[train[1][i]] + train[0][i]\n",
    "    except:\n",
    "        m[train[1][i]] = train[0][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = set()\n",
    "for i in m:\n",
    "    unique_words = unique_words | set(m[i])\n",
    "unique_words_count = len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_frequency = {}\n",
    "class_count = {}\n",
    "counter = 0\n",
    "for i in unique_labels:\n",
    "    current_count = len(Counter(m[i]))\n",
    "    class_count[i] = current_count\n",
    "    counter += current_count\n",
    "    ll = Counter(m[i])\n",
    "    for j in ll:\n",
    "        class_frequency[i, j] = ll[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_freq(word, label):\n",
    "    try:\n",
    "        return class_frequency[label, word], class_count[label]\n",
    "    except:\n",
    "        return 0, class_count[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_frequency) == counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_class_split = Counter(train[1])\n",
    "true = []\n",
    "predicted = []\n",
    "for i in range(test.shape[0]):\n",
    "    true.append(test[1][i])\n",
    "    classes_words_probability = []\n",
    "    for l in unique_labels:\n",
    "        words_probability = 0\n",
    "        for word in test[0][i]:\n",
    "            fr, cn = get_word_freq(word, l)\n",
    "            pp = (fr + 1)/(cn + unique_words_count)\n",
    "            words_probability += np.log(pp)\n",
    "        words_probability += np.log(train_class_split[l] / train.shape[0])\n",
    "        classes_words_probability.append(words_probability)\n",
    "    predicted.append(unique_labels[np.argmax(classes_words_probability)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[501,   0,   9,   6,   1],\n",
       "       [  1, 483,   6,   4,   5],\n",
       "       [  3,   0, 451,   1,   0],\n",
       "       [  5,   2,   8, 482,   4],\n",
       "       [  6,   2,  21,   8, 491]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_confusion(predicted, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9632"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_accuracy(predicted, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110804\n",
      "101130\n",
      "129503\n",
      "111274\n",
      "102056\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "for i in m:\n",
    "    print(len(m[i]))\n",
    "    corpus = corpus + m[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "554767"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = {}\n",
    "\n",
    "n = 0\n",
    "for tokens in train[0]:\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            DF[w].add(n)\n",
    "        except:\n",
    "            DF[w] = {n}\n",
    "    n += 1\n",
    "for i in DF:\n",
    "    DF[i] = len(DF[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_freq(word):\n",
    "    c = 0\n",
    "    try:\n",
    "        c = DF[word]\n",
    "    except:\n",
    "        pass\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "554767"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = {}\n",
    "N = train.shape[0]\n",
    "\n",
    "counter = Counter(corpus)\n",
    "words_count = len(corpus)\n",
    "\n",
    "for token in set(corpus):\n",
    "    tf = counter[token]/words_count\n",
    "    df = doc_freq(token)\n",
    "    idf = np.log((N+1)/(df+1))\n",
    "\n",
    "    tf_idf[token] = tf*idf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_x = sorted(tf_idf.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refined_data = {}\n",
    "# for i in sorted_x:\n",
    "#     try:\n",
    "#         if len(refined_data[i[0][0]])<topk:\n",
    "#             refined_data[i[0][0]].add(i[0][1])\n",
    "#     except:\n",
    "#         refined_data[i[0][0]] = {i[0][1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85789"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_data = sorted_x[:int(len(sorted_x)*percentage/100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_data = [i[0] for i in refined_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words_count = len(sorted_x[:int(len(sorted_x)*percentage/100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_frequency = {}\n",
    "class_count = {}\n",
    "for i in unique_labels:\n",
    "    ll = Counter(m[i])\n",
    "    for j in refined_data:\n",
    "        class_frequency[i, j] = ll[j]\n",
    "        try:\n",
    "            class_count[i] = class_count[i] + ll[j]\n",
    "        except:\n",
    "            class_count[i] = ll[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79110"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_count['sci.med']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_freq(word, label):\n",
    "    try:\n",
    "        return class_frequency[label, word], class_count[label]\n",
    "    except:\n",
    "        return 0, class_count[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class_split = Counter(train[1])\n",
    "true = []\n",
    "predicted = []\n",
    "for i in range(test.shape[0]):\n",
    "    true.append(test[1][i])\n",
    "    classes_words_probability = []\n",
    "    for l in unique_labels:\n",
    "        words_probability = 0\n",
    "        for word in test[0][i]:\n",
    "            fr, cn = get_word_freq(word, l)\n",
    "            pp = (fr + 1) / (cn + unique_words_count)\n",
    "            words_probability += np.log(pp)\n",
    "        words_probability += np.log(train_class_split[l] / train.shape[0])\n",
    "        classes_words_probability.append(words_probability)\n",
    "    predicted.append(unique_labels[np.argmax(classes_words_probability)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[511,   1,  12,  20,   8],\n",
       "       [  0, 482,   3,   1,   5],\n",
       "       [  2,   1, 474,   4,  27],\n",
       "       [  3,   1,   5, 475,  16],\n",
       "       [  0,   2,   1,   1, 445]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_confusion(predicted, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9548"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_accuracy(predicted, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
