{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Monitor the Environment in Azure Machine Learning (Telemetry)\n",
        "\n",
        "In this hands-on lab scenario you are a Data Scientist for Awesome Company. Recently the company has been using Azure Machine Learning Service to implement and run their machine learning workloads concerning diabetes research. With these services now being deployed to production, there is a need to monitor both the model telemetry and data drift.\n",
        "\n",
        "To accomplish your goal, the following should be completed:\n",
        "* **Use Azure Application Insights to monitor activity for a model service endpoint**\n",
        "* Configure data drift monitoring for a dataset\n",
        "\n",
        "*This example notebook is adopted from openly available Microsoft Learn material.*"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to your workspace"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to work with', ws.name)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1621965588897
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare a model for deployment"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\n",
        "from azureml.core import Model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from azureml.core import Dataset\n",
        "\n",
        "# Upload data files to the default datastore\n",
        "default_ds = ws.get_default_datastore()\n",
        "default_ds.upload_files(files=['./data/diabetes.csv', './data/diabetes2.csv'],\n",
        "                       target_path='diabetes-data/',\n",
        "                       overwrite=True,\n",
        "                       show_progress=True)\n",
        "\n",
        "#Create a tabular dataset from the path on the datastore\n",
        "print('Creating dataset...')\n",
        "data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
        "\n",
        "# Register the tabular dataset\n",
        "print('Registering dataset...')\n",
        "try:\n",
        "    data_set = data_set.register(workspace=ws, \n",
        "                               name='diabetes dataset',\n",
        "                               description='diabetes data',\n",
        "                               tags = {'format':'CSV'},\n",
        "                               create_new_version=True)\n",
        "except Exception as ex:\n",
        "    print(ex)\n",
        "\n",
        "# Create an Azure ML experiment in your workspace\n",
        "experiment = Experiment(workspace=ws, name='mslearn-train-diabetes')\n",
        "run = experiment.start_logging()\n",
        "print(\"Starting experiment:\", experiment.name)\n",
        "\n",
        "# load the diabetes dataset\n",
        "print(\"Loading Data...\")\n",
        "diabetes = data_set.to_pandas_dataframe()\n",
        "\n",
        "# Separate features and labels\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
        "\n",
        "# Split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# Train a decision tree model\n",
        "print('Training a decision tree model')\n",
        "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
        "\n",
        "# calculate accuracy\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# calculate AUC\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "run.log('AUC', np.float(auc))\n",
        "\n",
        "# Save the trained model\n",
        "model_file = 'diabetes_model.pkl'\n",
        "joblib.dump(value=model, filename=model_file)\n",
        "run.upload_file(name = 'outputs/' + model_file, path_or_stream = './' + model_file)\n",
        "\n",
        "# Complete the run\n",
        "run.complete()\n",
        "\n",
        "# Register the model\n",
        "print('Registering model...')\n",
        "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
        "                   tags={'Training context':'Inline Training'},\n",
        "                   properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
        "\n",
        "# Get the registered model\n",
        "model = ws.models['diabetes_model']\n",
        "\n",
        "print('Model trained and registered.')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1621965631623
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy a model as a web service"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create an experiment folder."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folder_name = 'diabetes_service'\n",
        "\n",
        "# Create a folder for the web service files\n",
        "experiment_folder = './' + folder_name\n",
        "os.makedirs(experiment_folder, exist_ok=True)\n",
        "\n",
        "print(folder_name, 'folder created.')\n",
        "\n",
        "# Set path for scoring script\n",
        "script_file = os.path.join(experiment_folder,\"score_diabetes.py\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1621965639553
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create script that the service will be used to score new data."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $script_file\n",
        "import json\n",
        "import joblib\n",
        "import numpy as np\n",
        "from azureml.core.model import Model\n",
        "\n",
        "# Called when the service is loaded\n",
        "def init():\n",
        "    global model\n",
        "    # Get the path to the deployed model file and load it\n",
        "    model_path = Model.get_model_path('diabetes_model')\n",
        "    model = joblib.load(model_path)\n",
        "\n",
        "# Called when a request is received\n",
        "def run(raw_data):\n",
        "    # Get the input data as a numpy array\n",
        "    data = json.loads(raw_data)['data']\n",
        "    np_data = np.array(data)\n",
        "    # Get a prediction from the model\n",
        "    predictions = model.predict(np_data)\n",
        "    \n",
        "    # print the data and predictions (so they'll be logged!)\n",
        "    log_text = 'Data:' + str(data) + ' - Predictions:' + str(predictions)\n",
        "    print(log_text)\n",
        "    \n",
        "    # Get the corresponding classname for each prediction (0 or 1)\n",
        "    classnames = ['not-diabetic', 'diabetic']\n",
        "    predicted_classes = []\n",
        "    for prediction in predictions:\n",
        "        predicted_classes.append(classnames[prediction])\n",
        "    # Return the predictions as JSON\n",
        "    return json.dumps(predicted_classes)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a Conda configuration file for the service environment."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.conda_dependencies import CondaDependencies \n",
        "\n",
        "# Add the dependencies for our model (AzureML defaults is already included)\n",
        "myenv = CondaDependencies()\n",
        "myenv.add_conda_package(\"scikit-learn\")\n",
        "\n",
        "# Save the environment config as a .yml file\n",
        "env_file = folder_name + \"/diabetes_env.yml\"\n",
        "with open(env_file,\"w\") as f:\n",
        "    f.write(myenv.serialize_to_string())\n",
        "print(\"Saved dependency info in\", env_file)\n",
        "\n",
        "# Print the .yml file\n",
        "with open(env_file,\"r\") as f:\n",
        "    print(f.read())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "gather": {
          "logged": 1621965654799
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deploy the service as an Azure Container Instance (ACI).\n",
        "\n",
        "**Note**: This can take a few minutes - wait until the state is shown as \"Healthy\"."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.webservice import AciWebservice, Webservice\n",
        "from azureml.core.model import Model\n",
        "from azureml.core.model import InferenceConfig\n",
        "\n",
        "# Configure the scoring environment\n",
        "inference_config = InferenceConfig(runtime= \"python\",\n",
        "                                   entry_script=script_file,\n",
        "                                   conda_file=env_file)\n",
        "\n",
        "service_name = \"diabetes-service-app-insights\"\n",
        "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
        "aci_service = Model.deploy(workspace=ws,\n",
        "                           name= service_name,\n",
        "                           models= [model],\n",
        "                           inference_config= inference_config,\n",
        "                           deployment_config=deployment_config)\n",
        "aci_service.wait_for_deployment(show_output = True)\n",
        "print(aci_service.state)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1621966324919
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enable Application Insights"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Enable AppInsights\n",
        "aci_service.update(enable_app_insights=True)\n",
        "print('AppInsights enabled!')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1621966347493
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use the web service"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Determine the URL for submitting requests."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint = aci_service.scoring_uri\n",
        "print(endpoint)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1621966356376
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make a call to the URI with the patient data and receive a predicted result.\n",
        "\n",
        "**Note**: If you receive an error, it might not be ready yet. Try again after a few moments."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# Create new data for inferencing\n",
        "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22],\n",
        "         [0,148,58,11,179,39.19207553,0.160829008,45]]\n",
        "\n",
        "# Convert the array to a serializable list in a JSON document\n",
        "input_json = json.dumps({\"data\": x_new})\n",
        "\n",
        "# Set the content type\n",
        "headers = { 'Content-Type':'application/json' }\n",
        "\n",
        "# Get the predictions\n",
        "predictions = requests.post(endpoint, input_json, headers = headers)\n",
        "print(predictions.status_code)\n",
        "if predictions.status_code == 200:\n",
        "    predicted_classes = json.loads(predictions.json())\n",
        "    for i in range(len(x_new)):\n",
        "        print (\"Patient {}\".format(x_new[i]), predicted_classes[i] )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "gather": {
          "logged": 1621966371472
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## View the logged data\n",
        "\n",
        "1. Return to your Machine Learning workspace.\n",
        "2. On the **Overview** page, click the link for the associated **Application Insights** resource.\n",
        "3. On the Application Insights blade, click **Logs**. \n",
        "4. Paste the following query into the query editor and click **Run**\n",
        "    ```\n",
        "    traces\n",
        "    |where customDimensions.[\"Service Name\"] == \"diabetes-service-app-insights\"\n",
        "    |project timestamp, customDimensions.Content\n",
        "    ```\n",
        "\n",
        "**Note**: It may take several minutes for the data to show up. Keep trying every five minutes until results display."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}